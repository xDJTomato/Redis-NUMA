# 01-numa-pool.md - NUMA内存池模块设计规范

## 文档概述

**类型**: 设计规范文档  
**版本**: v1.0  
**最后更新**: 2026-02-14

本文档定义NUMA内存池模块的核心设计规范，包括架构设计、接口规范、数据结构和核心算法。

**相关文档**:
- [09-memory-fragmentation-analysis.md](./09-memory-fragmentation-analysis.md) - 问题分析与优化方案
- [02-numa-migrate.md](./02-numa-migrate.md) - NUMA迁移模块
- [03-zmalloc-numa.md](./03-zmalloc-numa.md) - zmalloc NUMA适配

## 模块概述

### 功能定位

为每个NUMA节点提供独立的内存池管理，通过批量分配和对象重用来减少`numa_alloc_onnode`系统调用，从而提升内存分配性能。

### 设计原则

1. **性能优先**: O(1)时间复杂度的分配算法
2. **NUMA感知**: 每节点独立内存池，减少跨节点访问
3. **线程安全**: per-pool互斥锁，最小化锁竞争
4. **简单可靠**: 避免复杂回收机制，程序结束时统一清理

### 核心约束

- 最大分配对象: 512字节 (超过则直调用numa_alloc_onnode)
- 固定chunk大小: 64KB (所有size_class共享)
- 大小级别数量: 8级 (16/32/64/128/256/512/1024/2048字节)
- 不单独释放池内存: 简化实现，避免碎片回收复杂度

---

## 业务调用链

```
┌─────────────────────────────────────────────────────────────┐
│  调用入口                                                    │
│  zmalloc.c: numa_alloc_with_size()                          │
└──────────────────────────┬──────────────────────────────────┘
                           │ numa_pool_alloc(size, node, &alloc_size)
                           ▼
┌─────────────────────────────────────────────────────────────┐
│  numa_pool.c: numa_pool_alloc()                             │
│  1. 检查size <= NUMA_POOL_MAX_ALLOC (512B)                  │
│  2. 查找合适的大小级别 (16/32/64/128/256/512/1024/2048)     │
│  3. 获取对应节点的pool                                      │
│  4. 加锁 (pthread_mutex_lock)                               │
│  5. 尝试从现有chunk分配 (bump pointer)                      │
│  6. 如无空间，分配新64KB chunk                              │
│  7. 解锁                                                    │
│  8. 返回内存地址                                            │
└──────────────────────────┬──────────────────────────────────┘
                           │ 回退：numa_alloc_onnode()
                           ▼
┌─────────────────────────────────────────────────────────────┐
│  libnuma: numa_alloc_onnode()                               │
└─────────────────────────────────────────────────────────────┘
```

---

## 核心数据结构

### 1. 内存块 (numa_pool_chunk_t)

```c
typedef struct numa_pool_chunk {
    void *memory;                  /* NUMA-allocated memory */
    size_t size;                   /* Chunk size (64KB) */
    size_t offset;                 /* Current allocation offset */
    struct numa_pool_chunk *next;  /* Next chunk in list */
} numa_pool_chunk_t;
```

**内存布局**:
```
Chunk (64KB):
├─ offset: 0      ├─ offset: 256   ├─ offset: 512   ├─ ...
│  [alloc 1]      │  [alloc 2]     │  [alloc 3]     │
│  256 bytes      │  256 bytes     │  256 bytes     │
└─────────────────┴────────────────┴────────────────┘
```

### 2. 大小级别池 (numa_size_class_pool_t)

```c
typedef struct {
    size_t obj_size;               /* Object size for this class */
    numa_pool_chunk_t *chunks;     /* Chunk list */
    pthread_mutex_t lock;          /* Thread safety */
    size_t chunks_count;           /* Statistics */
} numa_size_class_pool_t;
```

### 3. 节点池 (numa_node_pool_t)

```c
typedef struct numa_node_pool {
    int node_id;
    numa_size_class_pool_t pools[NUMA_POOL_SIZE_CLASSES];  /* 8 pools */
    numa_pool_stats_t stats;
} numa_node_pool_t;
```

### 4. 全局上下文

```c
static struct {
    int initialized;
    int numa_available;
    int num_nodes;
    int current_node;
    numa_node_pool_t *node_pools;  /* Array of node pools */
    pthread_mutex_t init_lock;
} pool_ctx;
```

---

## 核心算法

### 1. Bump Pointer分配算法

```c
/* 伪代码 */
void *bump_pointer_alloc(pool, size) {
    aligned_size = (size + 15) & ~15;  /* 16-byte align */
    
    for each chunk in pool.chunks {
        if (chunk.offset + aligned_size <= chunk.size) {
            ptr = chunk.memory + chunk.offset;
            chunk.offset += aligned_size;
            return ptr;
        }
    }
    
    /* No space, allocate new chunk */
    new_chunk = alloc_new_chunk(pool);
    add to pool.chunks;
    return bump_pointer_alloc(pool, size);  /* Retry */
}
```

**时间复杂度**: O(1) - 通常第一个chunk就有空间

### 2. 大小级别选择

```c
static const size_t numa_pool_size_classes[8] = {
    16, 32, 64, 128, 256, 512, 1024, 2048
};

/* 选择逻辑 */
for (int i = 0; i < NUMA_POOL_SIZE_CLASSES; i++) {
    if (alloc_size <= numa_pool_size_classes[i]) {
        return &node_pool->pools[i];
    }
}
```

---

## 配置参数

| 参数 | 值 | 说明 |
|------|-----|------|
| NUMA_POOL_SIZE_CLASSES | 8 | 大小级别数量 |
| NUMA_POOL_CHUNK_SIZE | 64KB | 每个chunk的大小 |
| NUMA_POOL_MAX_ALLOC | 512B | 内存池分配的最大对象 |
| Size Classes | 16/32/64/128/256/512/1024/2048 | 各级别大小 |

---

## 接口函数

### 初始化与清理

```c
int numa_pool_init(void);           /* 初始化所有节点的内存池 */
void numa_pool_cleanup(void);       /* 清理所有内存池 */
```

### 内存分配与释放

```c
void *numa_pool_alloc(size_t size, int node, size_t *total_size);
void numa_pool_free(void *ptr, size_t total_size, int from_pool);
```

### 节点管理

```c
void numa_pool_set_node(int node);
int numa_pool_get_node(void);
int numa_pool_num_nodes(void);
int numa_pool_available(void);
```

### 统计信息

```c
void numa_pool_get_stats(int node, numa_pool_stats_t *stats);
void numa_pool_reset_stats(void);
```

---

## 性能数据

### 基准测试结果 (初期)

| 指标 | 无内存池 | 有内存池 | 提升 |
|------|---------|---------|------|
| SET | 25K req/s | 166K req/s | 6.6x |
| GET | 27K req/s | 166K req/s | 6.2x |
| 延迟p50 | 1-2ms | 0.15-0.2ms | 10x |

### 压力测试评估 (2026-02-14)

**测试配置**:
- 目标: 填充2GB数据 (约200万个2KB对象)
- 环境: 单NUMA节点, 15.6GB总内存
- 并发: 20客户端, 管道深度8

**实际结果**:

| 指标 | 目标值 | 实际值 | 差异 |
|------|--------|--------|------|
| SET性能 (初期) | 150-180K | 161K | 正常 |
| SET性能 (后期) | 150-180K | 100-112K | -20~40% |
| 内存碎片率 | <1.3 | **2.36** | +82% |
| 内存效率 | >80% | **42%** | -48% |
| 数据填充量 | 2.0GB | 1.0GB (49万keys) | 50% |
| 物理内存占用 | 预期2.5GB | **2.4GB** | 正常 |
| 浪费内存 | <500MB | **1.4GB** | 严重 |

**关键发现**:

1. **严重内存碎片** 🔴
   - 碎片率2.36远超正常阈值(1.3)
   - 存储1GB数据却占用2.4GB物理内存
   - 58%的内存被浪费在碎片上
   - `allocator_frag_bytes`: 1467MB

2. **性能下降** 🟡  
   - 初期: 160K req/s
   - 中期: 100K req/s (下降38%)
   - 后期: 112K req/s (稳定但低于预期)

3. **提前达到内存上限** 🔴
   - 计划填充200万keys
   - 实际仅填充49万keys (24%)
   - 40秒后内存即达2.4GB上限

4. **大内存块异常** 🟡
   - 出现8个超大块(>64MB)
   - 说明chunk合并机制缺失或系统直接mmap

---

## 设计决策

### 为什么使用64KB chunk？

- 覆盖Redis大部分小对象（sds、robj等）
- 64KB = 128个512B对象，命中率合理
- 与Linux页大小对齐，减少内存碎片

### 为什么池内存不单独释放？

**原设计理念**:
- Redis是长期运行的内存数据库
- 小对象频繁分配/释放，池内存会被快速重用
- 简化实现，避免复杂的内存回收机制
- 程序结束时统一清理所有chunks

**压力测试暴露的问题**:
- 碎片永久累积，无法回收
- 长期运行后碎片率高达2.36 (正常<1.3)
- 内存利用率仅42% (正常>80%)
- 需要引入阈值释放或compact机制

### 为什么使用per-pool锁而非全局锁？

- 不同大小级别的分配互不干扰
- 减少锁竞争，提高并发性能
- 每个pool独立管理自己的chunks

---

## 已知问题与优化方向

### 当前设计的局限性

基于2026-02-14压力测试评估，当前简单内存池设计存在以下问题：

#### 1. 固定chunk大小不灵活 🔴

**问题描述**:
- 64KB固定大小对所有size_class都相同
- 小对象(16-256B)浪费空间，大对象(1-2KB)填充慢
- 测试中大量2KB对象导致严重碎片

**示例**:
```
64KB chunk + 2KB对象 = 每chunk仅32个对象
如果请求模式不均匀，chunk利用率<50%
```

**优化方向**:
```c
// 动态chunk大小策略
size <= 256B   → 16KB chunk  (更密集)
size <= 1KB    → 64KB chunk  (当前)
size <= 4KB    → 256KB chunk (减少分配次数)
size > 4KB     → 直接mmap    (避免池碎片)
```

#### 2. 8级size_class分级太粗 🟡

**问题描述**:
- 当前: 16/32/64/128/256/512/1024/2048
- Redis对象大小范围广: robj(16B) + sds + value
- 跨级对齐造成内部碎片

**示例**:
```
请求100B → 分配128B → 浪费28B (22%)
请求300B → 分配512B → 浪费212B (41%)
```

**优化方向**:
```c
// 扩展到16级，减少浪费
const size_t size_classes[16] = {
    16, 32, 48, 64,          // 精细小对象
    96, 128, 192, 256,       // 中小对象
    384, 512, 768, 1024,     // 中等对象  
    1536, 2048, 3072, 4096   // 较大对象
};
```

#### 3. 不释放策略导致碎片累积 🔴

**问题描述**:
- 简化设计：池内存永不释放
- 副作用：碎片永久累积，无法回收
- 测试结果：碎片率2.36，浪费1.4GB内存

**优化方向**:
```c
// 方案1: 阈值释放
if (fragmentation_ratio > 1.5) {
    release_empty_chunks();  // 释放完全空闲的chunk
}

// 方案2: 后台compact
if (fragmentation_ratio > 1.8) {
    compact_pool();  // 迁移活跃对象，整理碎片
}
```

#### 4. 缺少分层内存池架构 🟡

**问题描述**:
- 所有对象共用同一套内存池
- 小对象和大对象混合，碎片严重
- 无法针对不同大小优化策略

**优化方向**:
```c
// 分层内存池设计
struct numa_tiered_pool {
    small_pool_t  small;   // <1KB:  细粒度slab
    medium_pool_t medium;  // 1-8KB: 当前策略
    large_pool_t  large;   // >8KB:  直接分配
};
```

### 优化路线图

#### 短期优化 (保持简单设计)

**优先级P0 - 立即实施**:
1. ✅ 调整chunk大小策略 (动态选择16/64/256KB)
2. ✅ 扩展size_class到16级
3. ✅ 引入碎片率监控和告警

**优先级P1 - 1-2周内**:
4. 实现阈值释放机制 (碎片率>1.5时释放空chunk)
5. 添加内存池统计API (暴露碎片率给INFO命令)
6. 优化bump pointer算法 (跳过已满chunk)

#### 中期优化 (架构调整)

**优先级P2 - 1个月内**:
7. 引入slab allocator机制 (参考jemalloc)
8. 实现分层内存池 (small/medium/large)
9. 添加后台compact任务 (定期整理碎片)

**优先级P3 - 长期**:
10. 实现per-thread cache (减少锁竞争)
11. 支持内存池动态扩缩容
12. 集成到NUMA迁移策略

### 性能目标

优化后的期望指标：

| 指标 | 当前值 | 目标值 |
|------|--------|--------|
| 碎片率 | 2.36 | <1.3 |
| 内存效率 | 42% | >80% |
| SET性能 | 100-160K | 150-180K |
| 填充成功率 | 24% | >90% |
| 内存浪费 | 1.4GB | <500MB |

### 测试计划

每次优化后需执行：

```bash
# 1. 快速功能测试
cd tests
./numa_cxl_stress_test.sh quick

# 2. 检查关键指标
cat reports/diagnosis_*/fragmentation.txt
cat reports/diagnosis_*/memory_timeline.csv

# 3. 完整压力测试
./numa_cxl_stress_test.sh full

# 4. 对比基准
cat reports/diagnosis_*/DIAGNOSIS_SUMMARY.txt
```

**成功标准**:
- 碎片率 < 1.3
- SET性能 > 150K req/s
- 能够填充90%以上的目标数据量
- 无OOM或性能严重下降
